{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "t3JsKhLCKXhI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "zSRS1cG73b0y"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, Lambda\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset Loaders"
      ],
      "metadata": {
        "id": "VlHhlvSKJzns"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def MNIST_loaders(train_batch_size=512, test_batch_size=1):\n",
        "\n",
        "    transform = Compose([\n",
        "        ToTensor(),\n",
        "        Normalize((0.1307,), (0.3081,)),\n",
        "        Lambda(lambda x: torch.flatten(x))])\n",
        "\n",
        "    train_loader = DataLoader(\n",
        "        MNIST('./data/', train=True,\n",
        "              download=True,\n",
        "              transform=transform),\n",
        "        batch_size=train_batch_size, shuffle=True)\n",
        "\n",
        "    test_loader = DataLoader(\n",
        "        MNIST('./data/', train=False,\n",
        "              download=True,\n",
        "              transform=transform),\n",
        "        batch_size=test_batch_size, shuffle=False)\n",
        "\n",
        "    return train_loader, test_loader"
      ],
      "metadata": {
        "id": "SJuiv3aCE9Sl"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Forward-Forward network"
      ],
      "metadata": {
        "id": "2yaaeTqrJ2vs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class ff_layer(nn.Linear):\n",
        "  def __init__(\n",
        "                self,\n",
        "                in_features, \n",
        "                out_features, \n",
        "                bias=True, \n",
        "                device=None, \n",
        "                dtype=None,\n",
        "                eps=1e-7,\n",
        "                threshold=3.,\n",
        "                standard=True\n",
        "              ):\n",
        "  \n",
        "    super(ff_layer, self).__init__(in_features, out_features, bias, device, dtype)\n",
        "\n",
        "    self.relu = nn.ReLU()\n",
        "    self.optimizer = torch.optim.Adam(self.parameters())\n",
        "    if standard == False:\n",
        "      self.criterion = nn.BCEWithLogitsLoss()\n",
        "    self.eps = eps\n",
        "    self.threshold = threshold\n",
        "    self.standard = standard\n",
        "\n",
        "  def forward(self, x):\n",
        "    x_norm = x / (torch.norm(x, dim=1, keepdim=True) + self.eps)\n",
        "    x_linear = super(ff_layer, self).forward(x_norm)\n",
        "    x_relu = self.relu(x_linear)\n",
        "    \n",
        "    return x_relu\n",
        "\n",
        "  def train_forward(self, x_pos, x_neg):\n",
        "    for i in range(1000): \n",
        "      x_pos_relu, x_neg_relu = self.forward(x_pos), self.forward(x_neg)\n",
        "\n",
        "      g_pos = x_pos_relu.pow(2).mean(1) \n",
        "      g_neg = x_neg_relu.pow(2).mean(1)\n",
        "\n",
        "      if self.standard==True:\n",
        "        loss = torch.log(1 + torch.exp(torch.cat([\n",
        "                    -g_pos + self.threshold,\n",
        "                    g_neg - self.threshold]))).mean()\n",
        "      else:\n",
        "        x = torch.cat((g_pos - self.threshold, g_neg + self.threshold))\n",
        "        y = torch.cat((torch.ones(g_pos.shape[0]), torch.zeros(g_neg.shape[0]))).to(device)\n",
        "        loss = self.criterion(x, y)\n",
        "      \n",
        "      self.optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      self.optimizer.step()\n",
        "\n",
        "    return self.forward(x_pos).detach(), self.forward(x_neg).detach()\n"
      ],
      "metadata": {
        "id": "bLicGWKB3wf2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(\n",
        "                self,\n",
        "                layers_size, \n",
        "                bias=True, \n",
        "                device=None, \n",
        "                dtype=None,\n",
        "                eps=1e-7,\n",
        "                threshold=3.\n",
        "            ):\n",
        "  \n",
        "    super(MLP, self).__init__()\n",
        "    self.layers = nn.ModuleList([\n",
        "        ff_layer(layers_size[i], layers_size[i+1], threshold=threshold, eps=eps) for i in range(len(layers_size)-1)\n",
        "    ])\n",
        "\n",
        "  def forward(self, x_pos, x_neg):\n",
        "    for i, layer in enumerate(self.layers):\n",
        "      x_pos, x_neg = layer.train_forward(x_pos, x_neg)\n",
        "\n",
        "  \n",
        "  def predict(self, x, y):\n",
        "    x_pos, x_neg = create_positive_negative(x, y)\n",
        "\n",
        "    for i, layer in enumerate(self.layers):\n",
        "      x_pos, x_neg = layer(x_pos), layer(x_neg)\n",
        "\n",
        "      if i == 0:\n",
        "        pos_goodness = x_pos.pow(2).mean(1).unsqueeze(-1)\n",
        "        neg_goodness = x_neg.pow(2).mean(1).unsqueeze(-1)\n",
        "        continue\n",
        "  \n",
        "      pos_goodness = torch.cat([pos_goodness, x_pos.pow(2).mean(1).unsqueeze(-1)], 1)\n",
        "      neg_goodness = torch.cat([neg_goodness, x_neg.pow(2).mean(1).unsqueeze(-1)], 1)\n",
        "    \n",
        "    return pos_goodness[:, 1:].max() > neg_goodness[:, 1:].max()\n"
      ],
      "metadata": {
        "id": "uXdc0luWm-OA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions to generate positives and negatives"
      ],
      "metadata": {
        "id": "gDp6BeKTKFfe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def insert_y_on_x(x, y, n_labels=10):\n",
        "    x_ = x.clone()\n",
        "    x_[:, :n_labels] *= 0.0\n",
        "    x_[range(x.shape[0]), y] = x.max()\n",
        "    return x_"
      ],
      "metadata": {
        "id": "w6bv2Eg1-n2K"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_positive_negative(x, y, n_labels=10):\n",
        "  x_pos = insert_y_on_x(x, y)\n",
        "  y_neg = list(range(10))\n",
        "  y_neg.remove(y)\n",
        "  x_neg = insert_y_on_x(x.repeat(n_labels-1, 1), y_neg)\n",
        "\n",
        "  return x_pos, x_neg"
      ],
      "metadata": {
        "id": "4N4vwBvy_oKp"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data and network"
      ],
      "metadata": {
        "id": "c5CcGVewKPuc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader, test_loader = MNIST_loaders()\n",
        "torch.manual_seed(1)\n",
        "network = MLP([784, 128, 128]).to(device)"
      ],
      "metadata": {
        "id": "xnPhZT6zAn1F"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model"
      ],
      "metadata": {
        "id": "_pA4LMsnKSIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "network.train()\n",
        "for images, y in tqdm(train_loader):\n",
        "  images = images.to(device)\n",
        "  y = y.to(device)\n",
        "  y_neg = torch.randint(0, 10, (images.shape[0],)).to(device)\n",
        "\n",
        "  for i in range(len(y_neg)):\n",
        "    if y_neg[i] == y[i]:\n",
        "      y_neg[i] = (y[i] + 1)%10\n",
        "\n",
        "\n",
        "  images_pos = insert_y_on_x(images, y)\n",
        "  images_neg = insert_y_on_x(images, y_neg)\n",
        "\n",
        "  \n",
        "  network(images_pos, images_neg)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXu6pJYhFWWe",
        "outputId": "8c8ba53f-06e1-4b55-ffa9-ac351e8d8ea0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 118/118 [06:27<00:00,  3.28s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Compute accuracy"
      ],
      "metadata": {
        "id": "mbtmGm8_KTyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "count_all = 0\n",
        "count_true = 0\n",
        "network.eval()\n",
        "for images, y in tqdm(test_loader):\n",
        "\n",
        "  images = images.to(device)\n",
        "  count_all+=1\n",
        "  if network.predict(images, y):\n",
        "    count_true+=1\n",
        "\n",
        "print(f\"\\nAccuracy: {count_true/count_all}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQnBnSAWM-UA",
        "outputId": "b1bebb54-710c-4838-ff2a-829fb9a62c80"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:18<00:00, 527.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}